# Welcome to my list of interesting projects!



## Markdown
[Markdown Syntax](https://www.markdownguide.org/basic-syntax/)
The Markdown elements outlined in the original design document.

[Markitdown](https://github.com/microsoft/markitdown)
Python tool for converting files and office documents to Markdown.



## Prompt Engineering
[Repo Prompt](https://repoprompt.com/)
Code smarter with AI—no more messy copy-pasting. Let Repo Prompt structure your prompts and apply AI changes for you.

[Prompt Perfect](https://promptperfect.jina.ai/)
(Prompt Optomiser



## Agentic frameworks
[AI Stuite](https://github.com/andrewyng/aisuite)
aisuite makes it easy for developers to use multiple LLM through a standardized interface. Using an interface similar to OpenAI's, aisuite makes it easy to interact with the most popular LLMs and compare the results. It is a thin wrapper around python client libraries, and allows creators to seamlessly swap out and test responses from different LLM providers without changing their code. Today, the library is primarily focussed on chat completions. We will expand it cover more use cases in near future.

[AutoGen](https://microsoft.github.io/autogen/stable/)
A programming framework for building conversational single and multi-agent applications. Built on Core. Requires Python 3.10+.

[Agency Swarm](https://vrsen.github.io/agency-swarm/)
we aim to simplify the agent creation process and enable anyone to create collaborative swarm of agents (Agencies), each with distinct roles and capabilities

[CrewAI-Studio](https://github.com/strnad/CrewAI-Studio)
Welcome to CrewAI Studio! This application provides a user-friendly interface written in Streamlit for interacting with CrewAI, suitable even for those who don't want to write any code. Follow the steps below to install and run the application on Windows or Linux (probably also MacOS) using either Conda or a virtual environment.

[Composio](https://composio.dev/)
Integration Platform for AI Agents & LLMs

[Dynamiq](https://dynamiq-ai.github.io/dynamiq/)
Dynamiq is your all-in-one Gen AI framework, designed to streamline the development of AI-powered applications. Dynamiq specialises in orchestrating retrieval-augmented generation (RAG) and large language model (LLM) agents.

[Microsoft.TinyTroupe](https://github.com/microsoft/TinyTroupe)
LLM-powered multiagent persona simulation for imagination enhancement and business insights.

[OctoTools](https://github.com/octotools/octotools)
A training-free, user-friendly, and easily extensible open-source agentic framework designed to tackle complex reasoning across diverse domains. OctoTools introduces standardized tool cards to encapsulate tool functionality, a planner for both high-level and low-level planning, and an executor to carry out tool usage.

[Pydantic AI](https://ai.pydantic.dev/)
Agno is a Python agent framework designed to make it less painful to build production grade applications with Generative AI.

[Agno]([https://www.phidata.com/](https://www.agno.com/))
Phidata is a framework for building multi-modal agents and workflows. Build agents with memory, knowledge, tools and reasoning. Build teams of agents that can work together to solve problems. Interact with your agents and workflows using a beautiful Agent UI.

[Swarms](https://docs.swarms.world/en/latest/)
Swarms aims to be the definitive and most reliable multi-agent LLM framework, offering developers the tools to automate business operations effortlessly. It provides a vast array of swarm architectures, seamless third-party integration, and unparalleled ease of use. With Swarms, developers can orchestrate intelligent, scalable agent ecosystems that can automate complex business processes.

[Smolagents](https://huggingface.co/docs/smolagents/index)
This library is the simplest framework out there to build powerful agents! By the way, wtf are “agents”? We provide our definition in this page, whe’re you’ll also find tips for when to use them or not (spoilers: you’ll often be better off without agents).

[Transformer Agents](https://huggingface.co/blog/agents)
License to Call: Introducing Transformers Agents 2.0



## Workflow
[Metaflow](https://metaflow.org/)
A framework for real-life ML, AI, and data science. Open-source Metaflow makes it quick and easy to build and manage real-life ML, AI, and data science projects.



## MLOps
[Comet](https://www.comet.com/site/)
Comet provides an end-to-end model evaluation platform for AI developers,

[CleanML](https://clear.ml/)
The Infrastructure Platform For AI Builders. Maximize AI Potential at Enterprise Scale

[Ear/y](https://www.startearly.ai/)
Use EarlyAI in conjunction with your favorite AI code generation assistant to maximize the quality of your code while accelerating development speed.
Your easy-to-use test engineering AI agent automates test code generation and proactively ensures that your code is kept free of bugs.

[unify](https://unify.ai/)
Build custom interfaces for: logging, evals, guardrails, labelling, tracing, agents, human-in-the-loop, hyperparam sweeps, and anything else you can think of ✨

[Uptrain](https://uptrain.ai/)
Full-stack LLMops platform for all your production needs from Evaluation to Experimentation to Improvement

[ZenML](https://github.com/zenml-io)
An open-source MLOps + LLMOps framework that seamlessly integrates existing infrastructure and tools



## Ops
[Icecream](https://github.com/gruns/icecream)
Never use print() to debug again

[Pytest](https://docs.pytest.org/en/stable/)
The pytest framework makes it easy to write small, readable tests, and can scale to support complex functional testing for applications and libraries.

[ruff](https://docs.astral.sh/ruff/)
An extremely fast Python linter and code formatter, written in Rust.

[PyRight](https://microsoft.github.io/pyright/#/)
Pyright is a full-featured, standards-compliant static type checker for Python. It is designed for high performance and can be used with large Python source bases.

[UV](https://github.com/astral-sh/uv)
An extremely fast Python package and project manager, written in Rust.



## LLM Memory / caching
[Letta](https://github.com/letta-ai/letta?tab=readme-ov-file)
Letta (formerly MemGPT) is a framework for creating LLM services with memory.

[mem0](https://github.com/mem0ai/mem0)
enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. Mem0 remembers user preferences, adapts to individual needs, and continuously improves over time, making it ideal for customer support chatbots, AI assistants, and autonomous systems.

[memary](https://github.com/kingjulio8238/Memary)
Agents promote human-type reasoning and are a great advancement towards building AGI and understanding ourselves as humans. Memory is a key component of how humans approach tasks and should be weighted the same when building AI agents. memary emulates human memory to advance these agents.

[MemoRAG](https://github.com/qhjqhj00/MemoRAG)
MemoRAG is an innovative RAG framework built on top of a highly efficient, super-long memory model. Unlike standard RAG, which primarily handles queries with explicit information needs, MemoRAG leverages its memory model to achieve a global understanding of the entire database. By recalling query-specific clues from memory, MemoRAG enhances evidence retrieval, resulting in more accurate and contextually rich response generation.​

[LMCache](https://github.com/LMCache/LMCache)
LMCache is a LLM serving engine extension to reduce TTFT and increase throughput, especially under long-context scenarios. By storing the KV caches of reusable texts across various locations including (GPU, CPU DRAM, Local Disk), LMCache reuse the KV caches of any reused text (not necessarily prefix) in any serving engine instance. Thus, LMCache saves precious GPU cycles and reduces response delay for users.

[LangMem](https://langchain-ai.github.io/langmem/)
LangMem helps agents learn and adapt from their interactions over time.

[Zep](https://github.com/getzep/zep)
The Memory Foundation For Your AI Stack

[A-Mem](https://github.com/agiresearch/A-mem)
A novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way.




## State
[Burr](https://burr.dagworks.io/)
Burr makes it easy to develop applications that make decisions (chatbots, agents, simulations, etc...) from simple python building blocks.
Burr works well for any application that uses LLMs, and can integrate with any of your favorite frameworks. Burr includes a UI that can track/monitor/trace your system in real time, along with pluggable persisters (e.g. for memory) to save & load application state.



## LLM inference / Serving Engines
[Guidance](https://github.com/guidance-ai/guidance)
Guidance is an efficient programming paradigm for steering language models. With Guidance, you can control how output is structured and get high-quality output for your use case—while reducing latency and cost vs. conventional prompting or fine-tuning. It allows users to constrain generation (e.g. with regex and CFGs) as well as to interleave control (conditionals, loops, tool use) and generation seamlessly.

[Ollama](https://ollama.com/)
Get up and running with large language models.

[vLLM](https://docs.vllm.ai/en/latest/)
vLLM is a fast and easy-to-use library for LLM inference and serving.

[LM Studio](https://lmstudio.ai/)
Discover. download, and run local LLMs

[LlamaFile](https://github.com/Mozilla-Ocho/llamafile)
Our goal is to make open LLMs much more accessible to both developers and end users. 

[LLaMA.cpp](https://github.com/ggml-org/llama.cpp)
The main goal of llama.cpp is to enable LLM inference with minimal setup and state-of-the-art performance on a wide range of hardware - locally and in the cloud.

[LitServe](https://github.com/Lightning-AI/LitServe?tab=readme-ov-file#performance)
LitServe is an easy-to-use, flexible serving engine for AI models built on FastAPI. It augments FastAPI with features like batching, streaming, and GPU autoscaling eliminate the need to rebuild a FastAPI server per model.

[Inception Labs])https://www.inceptionlabs.ai/)
Inception’s diffusion-based approach to language generation is inspired by advanced AI systems for images and video like Midjourney and Sora and provides unprecedented speed, quality, and generative control.

[Groq](https://groq.com/)
We provide fast AI inference in the cloud and in on-prem AI compute centers. We power the speed of iteration, fueling a new wave of innovation, productivity, and discovery. Groq was founded in 2016 to build technology to advance AI because we saw this moment coming. 

[Cerebras](https://cerebras.ai/)
Cerebras Inference Llama 3.3 70B runs at 2,200 tokens/s and Llama 3.1 405B at 969 tokens/s – over 70x faster than GPU clouds. Get instant responses to code-gen, summarization, and agentic tasks.

[Sambanova](https://sambanova.ai/)
We’ve built an enterprise-ready AI platform from the ground up – intentionally designed for the most valuable and complex AI workloads of today and tomorrow. Using our platform to build a technology backbone for the next decade of AI innovation, organizations get pre-trained foundation models that truly transform the way they gain value from AI and deep learning. And, with our flagship offering, SambaNova Suite, we help them realize value 22x faster.

[Together AI](https://www.together.ai/)
Train, fine-tune-and run inference on AI models blazing fast, at low cost, and at production scale.

[Predibase](https://predibase.com/)
Highest quality, fastest throughput small language models in your cloud



## RAG frameworks
[llmware](https://github.com/llmware-ai/llmware)
provides a unified framework for building LLM-based applications (e.g., RAG, Agents), using small, specialized models that can be deployed privately, integrated with enterprise knowledge sources safely and securely, and cost-effectively tuned and adapted for any business process.

[RAG-Zero-To-Hero](https://github.com/KalyanKS-NLP/rag-zero-to-hero-guide)




## Guardrails
[Guardrails](https://github.com/guardrails-ai/guardrails?tab=readme-ov-file)
Guardrails runs Input/Output Guards in your application that detect, quantify and mitigate the presence of specific types of risks. To look at the full suite of risks, check out [Guardrails Hub](https://hub.guardrailsai.com/).
Guardrails help you generate structured data from LLMs.

[NeMo](https://github.com/NVIDIA/NeMo-Guardrails)
NeMo Guardrails is an open-source [toolkit](https://docs.nvidia.com/nemo/guardrails/) for easily adding programmable guardrails to LLM-based conversational systems.

[LlamaGuard Vision](https://huggingface.co/meta-llama/Llama-Guard-3-11B-Vision)
Llama Guard 3 Vision is a Llama-3.2-11B pretrained model, fine-tuned for content safety classification. Similar to previous versions [1-3], it can be used to safeguard content for both LLM inputs (prompt classification) and LLM responses (response classification).

[LlamaGuard 3](https://huggingface.co/meta-llama/Llama-Guard-3-8B)
Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM – it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.

[DeepVal](https://github.com/confident-ai/deepeval)
DeepEval is a simple-to-use, open-source LLM evaluation framework, for evaluating and testing large-language model systems. It is similar to Pytest but specialized for unit testing LLM outputs. DeepEval incorporates the latest research to evaluate LLM outputs based on metrics such as G-Eval, hallucination, answer relevancy, RAGAS, etc., which uses LLMs and various other NLP models that runs locally on your machine for evaluation.

[CodeGate](https://codegate.ai/)
CodeGate is a guardian angel that sits between your AI assistants and LLMs, always shielding your privacy and supercharging your productivity.



## LLM Routers
[Aurelio](https://github.com/aurelio-labs/semantic-router)
Semantic Router is a superfast decision-making layer for your LLMs and agents. Rather than waiting for slow LLM generations to make tool-use decisions, we use the magic of semantic vector space to make those decisions — routing our requests using semantic meaning.

[aisuite](https://github.com/andrewyng/aisuite)
makes it easy for developers to use multiple LLM through a standardized interface. Using an interface similar to OpenAI's, aisuite makes it easy to interact with the most popular LLMs and compare the results. It is a thin wrapper around python client libraries, and allows creators to seamlessly swap out and test responses from different LLM providers without changing their code. 

[LLMSelector](https://github.com/LLMSELECTOR/LLMSELECTOR)
LLMSELECTOR is a framework that automatically optimizes model selection for compound AI systems!

[Requesty](https://requesty.ai/)
Develop, deploy, and monitor AI faster with more confidence, while extracting actionable insights from conversational data

[OpenRouter](https://openrouter.ai/)
A unified interface for LLMs

[RouteLLM](https://github.com/lm-sys/RouteLLM)
A framework for serving and evaluating LLM routers - save LLM costs without compromising quality



## Rerankers / Embeddings
[rerankers](https://github.com/answerdotai/rerankers)
A lightweight unified API for various reranking models. 

[Voyage Ai](https://www.voyageai.com/)
Supercharging Search and Retrieval for Unstructured Data

[Cohere](https://cohere.com/)
The all-in-one platform for private and secure AI

[Bert](https://www.sbert.net/)
Sentence Transformers (a.k.a. SBERT) is the go-to Python module for accessing, using, and training state-of-the-art text and image embedding models. It can be used to compute embeddings using Sentence Transformer models (quickstart) or to calculate similarity scores using Cross-Encoder models (quickstart). This unlocks a wide range of applications, including semantic search, semantic textual similarity, and paraphrase mining.

[Pylate](https://www.lighton.ai/lighton-blogs/pylate-flexible-training-and-retrieval-for-late-interaction-models)
A user-friendly library for training and experimenting with ColBERT models, a family of models that exhibit strong retrieval capabilities on out-of-domain data. Built on the sentence transformers framework, the library is designed to make training and experimenting with ColBERT models more accessible to researchers and practitioners to accelerate the research in this domain.



## Documentation
[mkdocs](https://github.com/squidfunk/mkdocs-material)
Write your documentation in Markdown and create a professional static site for your Open Source or commercial project in minutes – searchable, customizable, more than 60 languages, for all devices.



## MCP
[Model Context Protocol](https://github.com/modelcontextprotocol/servers/tree/main)
A collection of reference implementations and community-contributed servers for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP). This repository showcases the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.

[Composio](https://mcp.composio.dev/)
Instantly Connect to 100+ Managed MCP Servers with Built-In Auth

[MCPServers](https://mcpservers.org/)
A collection of servers for the Model Context Protocol.

[MCP.so](https://mcp.so/)
Find Awesome MCP Servers and Clients

[MCP Server Finder](https://www.mcpserverfinder.com/)
Find MCP servers and improve your workflow with AI

[Smithery](https://smithery.ai/)
Extend your agent with 2,232 capabilities via Model Context Protocol servers.




## Search Engines
[Brave Search API](https://brave.com/search/api/)
Power your search and AI apps with the fastest growing independent search engine since Bing. Access an index of billions of pages with a single call.

[Tavily](https://tavily.com/)
Empowering your AI applications with real-time, accurate search results tailored for LLMs and RAG.

[Linkup](https://www.linkup.so/)
Power your business applications with the world's most accurate web search and access to fresh, premium content.

[Jena AI](https://www.jena.ai)
Your search foundation supercharged.



## Distributed LLMs
[Exo](https://github.com/exo-explore/exo)
Run your own AI cluster at home with everyday devices



## Knowledge Graphs
[itext2KG](https://github.com/AuvaLab/itext2kg)
iText2KG is a Python package designed to incrementally construct consistent knowledge graphs with resolved entities and relations by leveraging large language models for entity and relation extraction from text documents. It features zero-shot capability, allowing for knowledge extraction across various domains without specific training. The package includes modules for document distillation, entity extraction, and relation extraction, ensuring resolved and unique entities and relationships. It continuously updates the KG with new documents and integrates them into Neo4j for visual representation.



## Chunking
[Chonkie](https://github.com/chonkie-ai/chonkie)
The no-nonsense RAG chunking library that’s lightweight, lightning-fast, and ready to CHONK your texts.

[Semchunk](https://github.com/umarbutler/semchunk)
A fast and lightweight pure Python library for splitting text into semantically meaningful chunks.



## Data Validation & Structure Output
[Pydantic](https://docs.pydantic.dev/latest/)
Data validation using Python type hints.

[Instructor](https://python.useinstructor.com/)
Structured outputs powered by llms. Designed for simplicity, transparency, and control.

[Outlines](https://github.com/dottxt-ai/outlines)
Outlines provides ways to control the generation of language models to make their output more predictable.



## Fine-Tunning
[Unsloth](https://unsloth.ai/)
Makes finetuning large language models like Llama-3, Mistral, Phi-3 and Gemma 2x faster, use 70% less memory, and with no degradation in accuracy!

[MLX](https://opensource.apple.com/projects/mlx/)
MLX is an array framework designed for efficient and flexible machine learning research on Apple silicon.

[Axoloti](https://axoloti.ai/)
MLX is an array framework designed for efficient and flexible machine learning research on Apple silicon.

[Covalent](https://www.covalent.xyz/)
Effortless AI Compute for Any Environment.

[Encord](https://encord.com/)
Manage, curate, and label multimodal data such as image, video, audio, document, text and DICOM files – all on one platform. Transform petabytes of unstructured data into high quality data for training, fine-tuning, and aligning AI models, fast.

[Transformer Labs](https://transformerlab.ai/)
100% Open Source Toolkit for Large Language Models: Train, Tune, Chat on your own Machine



## Web Assistants
[Anima](https://www.animaapp.com/)
Turn your design into a live web app

[Builder](https://www.builder.io/)
Take Ideas to Production in Seconds, Not Sprints

[Bolt](https://bolt.new/)
What do you want to build?

[BindAI](https://app.getbind.co/)
Create full stack web applications with simple prompts with IDE

[Base44](https://base44.com/)
Turn your ideas into products, in minutes.

[Blackbox](https://www.blackbox.ai/builder)
What do you want to build today?

[Cerebras Code](https://cerebrascoder.com/)
Dream it. Code it. Instantly.

[create](https://www.create.xyz/)
urn your words into sites, tools, apps and products - built with code. Add GPT-4o and 40+ integrations in an instant.

[Dora](https://www.dora.run/ai)
Sites beyond imagination, one prompt away.

[Deepsite](https://enzostvs-deepsite.hf.space/)
DEEPSITE offers an End-to-end AI document processing automation solution (RPA) that captures data from any documents instantly, like supply chain documents ...

**[FirebaseStudiio](https://firebase.studio/)**
The full  stack AI workspace

[Figma](https://www.figma.com/)
Think bigger. Build faster.

[FlutterFlow](https://www.flutterflow.io/)
Build Better. Launch Faster.

[GroqLabs](https://appgen.groqlabs.com/)
Build a micro-app

[Gamma](https://gamma.app/)
A new medium for presenting ideas. Powered by AI

[HeyBoss](https://www.heyboss.xyz/)
World's 1st AI engineer for non-coders. Type your idea and AI will code your app, sites, and games in minutes, no coding required

[Hostinger](https://www.hostinger.com/horizons)
Bring your idea to life in minutes

[Lovable](https://lovable.dev/)
Idea to app in seconds

[MagicPatterns](https://www.magicpatterns.com/)
Build prototypes, get user feedback, and make data-driven decisions. The AI prototyping platform for product teams.

[Mastra](https://mastra.ai/)
From the team that brought you Gatsby: prototype and productionize AI features with a modern Javascript stack.

[Nutt](https://www.nut.new/)
Get what you want. Write, test, and fix your app all from one prompt

[Polymet](https://www.polymet.ai/)
Design and iterate faster with AI. Get the production-ready code and ship faster

[Pythagora](https://www.pythagora.ai/)
Turn Ideas Into Launched Projects

**[Play](https://createwithplay.com/)**
The most powerful tool to design and ship your apps.

[PixelFreeStudio](https://pixelfreestudio.com/index.html)
Design to Code in one Click (Figma)

[Relume](https://www.relume.io/)
Websites design & build faster with AI

[Replit](https://replit.com/)
Turn your ideas into apps. What will you create? The possibilities are endless.

[Sitebrew](https://www.sitebrew.ai/create)
Generate a site and share it with the world, in seconds

[Same New](https://same.new/)
Copy any UI

[Tempo](https://www.tempo.new/)
Build react apps 10x faster

[UXPilot](https://uxpilot.ai/)

[V0](https://v0.dev/)
What can I help you ship?




## Model Assistants
[Ai2 Scholar](https://scholarqa.allen.ai/)
Synthesizing 8M+ open access papers. A project from Ai2 and Semantic Scholar. Ai2 Scholar QA can make mistakes. Check source documents by following citations.

[Deepseek](https://chat.deepseek.com/sign_in)
Deepseek chat

[Grok](https://grok.com/)

[Gemini Coding Partner](https://gemini.google.com/gem/coding-partner)
Level up your coding skills. Get the help you need to build your projects and learn as you go.

[Gemini Coder](https://huggingface.co/spaces/osanseviero/gemini-coder)
Turn your idea into an app

[Google AI Studio](https://aistudio.google.com/prompts/new_chat)
Push Gemini to the limits of what Al can do using the Gemini API

[Kimi](https://kimi.moonshot.cn/)

[Mercury by Inception Labs](https://chat.inceptionlabs.ai/)

[Proxy](https://convergence.ai/)
Your AI assistant for your daily tasks

[Scira](https://scira.app/)
What do you want to explore?

[Val Town](https://www.val.town/townie/8011cb54-26e0-40b2-b514-64864f3d5dfb)
Create a val using Townie, the Val Town bot





## Code Assistants
[Aider](https://aider.chat/)
Aider lets you pair program with LLMs, to edit code in your local git repository. Start a new project or work with an existing code base. Aider works best with Claude 

[Augment Code](https://www.augmentcode.com/)
The first AI coding assistant built for professional software engineers and large codebases.

[Bolt.diy](https://stackblitz-labs.github.io/bolt.diy/)
This fork of Bolt.new (oTToDev) allows you to choose the LLM that you use for each prompt! Currently, you can use OpenAI, Anthropic, Ollama, OpenRouter, Gemini, LMStudio, Mistral, xAI, HuggingFace, DeepSeek, or Groq models - and it is easily extended to use any other model supported by the Vercel AI SDK! See the instructions below for running this locally and extending it to include more models.

[Copy Coder](https://copycoder.ai/)
Built for the next generation of AI coders. Upload images of full applications, UI mockups, or custom designs and use our generated prompts to build your apps faster.

[Codestral](https://mistral.ai/news/codestral/)
Empowering developers and democratising coding with Mistral AI.

[CoPilot](https://github.com/features/copilot)
The AI editor for everyone

[Continue](https://www.continue.dev/)
The leading open-source AI code assistant. You can connect any models and any context to create custom autocomplete and chat experiences inside the IDE

[Cline](https://github.com/cline/cline)
Meet Cline, an AI assistant that can use your CLI aNd Editor.

[CodeLLM](https://codellm.abacus.ai/)
A revolutionary new AI Code Editor that helps you 10x your developer productivity! Bundled with AI super assistant ChatLLM

[Cody - Sourcegraph](https://sourcegraph.com/cody)
The enterprise AI code assistant

[Claude Code](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview)
Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster through natural language commands. By integrating directly with your development environment, Claude Code streamlines your workflow without requiring additional servers or complex setup.

[Databutton](https://databutton.com/)
Your vision. Your software. Built by AI.

[DeepClaude](https://deepclaude.com/)
Harness the power of DeepSeek R1's reasoning and Claude's creativity and code generation capabilities with a unified API and chat interface.

[Devin](https://app.devin.ai/)
Built to help ambitious engineering teams achieve more

[Gemini Code](https://codeassist.google/)
Gemini Code Assist: AI coding assistance for any language

[Goose](https://goose.ai/)
GooseAI makes deploying NLP services easier and more accessible for creative technologists building products on top of large language models. In short, GooseAI is a fully managed inference service delivered via API. With feature parity to other well known APIs, GooseAI delivers a plug-and-play solution for serving open source language models at the industry's best economics by simply changing 2 lines in your code.

[Junie](https://www.jetbrains.com/junie/)
Delegate your tasks, focus on the results. Explore a new way of coding – with the coding agent by JetBrains

[LlamaCode](https://llamacoder.together.ai/)
Together AI code assinstant using Llama and Deekpseek

[MarsCode](https://www.marscode.com/extension)
Your Ai Assistant that understands you better

[Openhands](https://www.all-hands.dev/)
Open Source Agents for Developers

**[Pieces](https://pieces.app/)**
The first AI that remembers everything you work on

[Qodo](https://www.qodo.ai/)
Generate confidence, not just code.

[Replit](https://replit.com/)
Turn your ideas into apps with AI.

[Roo Code](https://github.com/RooVetGit/Roo-Code)
Roo Code is an AI-powered autonomous coding agent that lives in your editor.

[Screenshot To Code](https://screenshottocode.com/)
Convert any screenshot or design to clean code (with support for most frameworks)

[Sweep](https://sweep.dev/)
The AI coding assistant built for JetBrains IDEs

[SuperMaven](https://supermaven.com/)
The fastest copilot. Supermaven lets you write code 2x faster with AI.

[Twinny](https://twinny.dev/)
A Privacy-First AI Extension with Distributed Network Capabilities

[Tabby](https://www.tabbyml.com/)
Secure, flexible, and transparent AI coding

[Tabmine](https://www.tabnine.com/)
Any agent can write code. Ours earn your devs' trust.

[ZenCoder](https://zencoder.ai/)
The AI Coding Agent. The most integrated, customizable, and intuitive coding agent—Zencoder handles the routine so you can focus on the vision.



## AI Automation / No Code
[AgentSpace](https://cloud.google.com/products/agentspace?hl=en)
The search and AI agent hub built for your work

[Active Pieces](https://www.activepieces.com/)
Automation software that's AI-first, no-code & open-source

[Dify](https://dify.ai/)
The Innovation Engine for GenAI Applications

[Gumloop](https://www.gumloop.com/)
Gumloop is a platform for automating complex work using AI via a no-code drag and drop interface. We want any person or business to be able to automate their work without needing to be AI experts or engineers.

[Julep](https://julep.ai/)
Deploy serverless AI workflows at scale

[Kestra](https://kestra.io/)
Unified Orchestration Platform to Simplify Business-Critical Workflows and Govern them as Code and from the UI.

[Langflow](https://www.langflow.org/)
Langflow is a low-code tool for developers that makes it easier to build powerful AI agents and workflows that can use any API, model, or database.

[MindStudio](https://www.mindstudio.ai/)
Create AI solutions–simple, fast, hassle-

[NocoCode](https://www.nocobase.com/)
Extensibility-first open-source no-code platform.
Total control, infinite extensibility, empower your team to swiftly adapt to changes and significantly reduce costs. Skip years of development and millions in investment - just deploy NocoBase in minutes.

[n8n](https://n8n.io/)
Secure, AI-native workflow automation. The world's most popular workflow automation platform for technical teams

[Pydantic Run](https://pydantic.run/)
A pydantic playgroud

[Render](https://render.com/)
Your fastest path to production

[TriggerDev](https://trigger.dev/)
The open source background jobs platform. Write workflows in normal async code and we’ll handle the rest, from queues to elastic scaling. No timeouts, retries, observability, and zero infrastructure to manage.




## IDE
[Cursor](https://www.cursor.com/)
Built to make you extraordinarily productive, Cursor is the best way to code with AI.

[Fleet](https://www.jetbrains.com/fleet/)
https://www.jetbrains.com/fleet/

[PearAI](https://trypear.ai/)
The AI Code Editor For Your Next Project

[Trae](https://www.trae.ai/)
Trae is an adaptive AI IDE that transforms how you work, collaborating with you to run faster.

[Theia](https://theia-ide.org/#theiaide)
A modern and open IDE for cloud and desktop. The Theia IDE is based on the Theia platform.

[Windsurf](https://codeium.com/windsurf)
The first agentic IDE, and then some. The Windsurf Editor is where the work of developers and AI truly flow together, allowing for a coding experience that feels like literal magic.

[Zed](https://zed.dev/)
The editor for what's next Zed is a next-generation code editor designed for high-performance collaboration with humans and AI.




## UI
[Gradio Playground](https://www.gradio.app/playground)

[CustomTkinter](https://customtkinter.tomschimansky.com/)
A modern and customizable python UI-library based on Tkinter

[Open WebUI](https://openwebui.com/)
Open WebUI is an extensible, self-hosted AI interface that adapts to your workflow, all while operating entirely offline.



## Recognition
[Gliner](https://github.com/urchade/GLiNER)
Generalist and Lightweight Model for Named Entity Recognition (Extract any entity types from texts)



## Multimodal libraries/models
[FastRTC](https://huggingface.co/blog/fastrtc)
FastRTC: The Real-Time Communication Library for Python

[SmolVLM2](https://huggingface.co/blog/smolvlm2)
SmolVLM2 represents a fundamental shift in how we think about video understanding - moving from massive models that require substantial computing resources to efficient models that can run anywhere. Our goal is simple: make video understanding accessible across all devices and use cases, from phones to servers.

[SigLIP2](https://huggingface.co/docs/transformers/main/en/model_doc/siglip2)
Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features

[GOT-OCR](https://github.com/Ucas-HaoranWei/GOT-OCR2.0)
AI models for OCR

[olmOCR](https://github.com/allenai/olmocr)
A toolkit for training language models to work with PDF documents in the wild.

[Mistral OCR](https://mistral.ai/en/news/mistral-ocr)
Mistral OCR is an Optical Character Recognition API that sets a new standard in document understanding. Unlike other models, Mistral OCR comprehends each element of documents—media, text, tables, equations—with unprecedented accuracy and cognition. It takes images and PDFs as input and extracts content in an ordered interleaved text and images.

[ColPali](https://huggingface.co/blog/manu/colpali)
Using Vision LLMs + late interaction to improve document retrieval (RAG, search engines, etc.), solely using the image representation of document pages

[SmolDocling](https://huggingface.co/ds4sd/SmolDocling-256M-preview)
SmolDocling is a multimodal Image-Text-to-Text model designed for efficient document conversion. It retains Docling's most popular features while ensuring full compatibility with Docling through seamless support for DoclingDocuments.

[Emoji Translate](https://emojitranslate.com/)
Translates emojis to various languages

[Emoji Fying LLMs](https://generativeai.pub/emoji-fying-llms-visualizing-ais-text-understanding-e2cee4957c5a)
Emoji-fying LLMs: Visualizing AI’s Text Understanding




## Agents
[TEN-Agent](https://github.com/TEN-framework/TEN-Agent)
A conversational AI powered by the TEN, integrating Gemini 2.0 Live, OpenAI Realtime, RTC, and more. It delivers real-time capabilities to see, hear, and speak, while being fully compatible with popular workflow platforms like Dify and Coze.

[Agno](https://www.agno.com/)
An open-source platform to build, ship and monitor agentic systems

[Manus](https://manus.im/)
Manus is a general AI agent that bridges minds and actions: it doesn't just think, it delivers results. Manus excels at various tasks in work and life, getting everything done while you rest.



## Edge AI
[SmallThinker](https://huggingface.co/PowerInfer/SmallThinker-3B-Preview)



## UI Testing
[Browser-use](https://browser-use.com/)
We make websites accessible for AI agents by extracting all interactive elements, so agents can focus on what makes their beer taste better.



## Image generation
[Recraft](https://www.recraft.ai/)
Vector Premium image generation and editing tool

[Diagramming AI](https://diagrammingai.com/)
Instantly Shape Your Ideas into Clear, Powerful Diagrams



## Evaluators
[Phoenix](https://docs.arize.com/phoenix)
Phoenix is an open-source observability library designed for experimentation, evaluation, and troubleshooting. It allows AI Engineers and Data Scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve.

[Deepval](https://docs.confident-ai.com/)
The open-source LLM evaluation framework

[Corrective RAG](https://lightning.ai/akshay-ddods/studios/build-a-corrective-rag-agentic-workflow-using-deepseek-r1?utm_campaign=akshay&utm_medium=linkedin)
In this studio we're building a corrective RAG (CRAG) agentic workflow. It's powered by a locally running DeepSeek-R1 and has ability to search through your docs, evaluate the context quality and fallback to web search if it needs more info.

[LangFuse](https://langfuse.com/)
Open Source LLM Engineering Platform. Traces, evals, prompt management and metrics to debug and improve your LLM application.


## Sandboxes
[E2B](https://github.com/e2b-dev)
We make it easy for developers to add code interpreting to AI apps with the E2B SDK

[ForeverVM](https://forevervm.com/)
Securely run AI-generated code in stateful sandboxes that run forever.

[Fly](https://fly.io/)
Give each of your users (or robots) a code execution sandbox that boots in milliseconds, runs any Docker image you throw at it, and scales to zero when you don't need it.



## Stores
[LanceDB](https://lancedb.com/)
LanceDB is a developer-friendly, open source database for AI. From hyper scalable vector search and advanced retrieval for RAG, to streaming training data and interactive exploration of large scale AI datasets, LanceDB is the best foundation for your AI application

[Milvus](https://milvus.io/)
The High-Performance. Vector Database Built for Scale

## Tools
[Bedrock Client for Mac](https://github.com/aws-samples/amazon-bedrock-client-for-mac)
A modern, native macOS client for Amazon Bedrock, providing streamlined access to AI models directly from your desktop.

[AINativeLanscapde](https://landscape.ainativedev.io/)
Your Guide to the AI Development Ecosystem

[NCCF Landscape 2](https://github.com/cncf/landscape2)
Landscape2 is a tool that generates interactive landscapes websites



